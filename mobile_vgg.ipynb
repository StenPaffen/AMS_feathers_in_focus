{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "bf0d7cbb",
      "metadata": {
        "id": "bf0d7cbb"
      },
      "source": [
        "### Dataset Description\n",
        "The dataset contains bird images, divided into train and test splits. The images are inside test_images and train_images folders.\n",
        "\n",
        "The labels of the training images are inside train_images.csv file. In this file, the first column is image_path and the second one is the label (1 - 200). The test_images_samples.csv includes a row id with a dummy label. The final goal of the challenge is to change the label column to the predicted label.\n",
        "\n",
        "The class_names.npy is a dictionary including the name of each label. Load the file using the following code: np.load(\"class_names.npy\", allow_pickle=True).item()\n",
        "\n",
        "The structure of the final submission should be exactly the same as the test_images_samples.csv! Otherwise, it will fail.\n",
        "\n",
        "Files\n",
        "\n",
        "- train_images - the training images\n",
        "- test_images - the test images\n",
        "- test_images_sample.csv - a sample submission file in the correct format\n",
        "- test_images_path.csv - path to test file images\n",
        "- train_images.csv - supplemental information about the data\n",
        "- class_names.npy - this file includes the name of each label\n",
        "- attributes.npy - this file includes the attributes which are extra information for each class.\n",
        "- attributes.txt - this file includes the attribute names which are extra information for each class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16124d83",
      "metadata": {
        "id": "16124d83"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8IjUfeZFEgz",
        "outputId": "cef7b1a4-6d55-40e3-f639-70ab32e41982"
      },
      "id": "h8IjUfeZFEgz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_data_path = '/content/drive/MyDrive/UvA Data Science/AMS_feathers_in_focus-main'\n",
        "\n",
        "#change gdrive wd\n",
        "os.chdir(base_data_path)\n",
        "print(f\"wd changed to: {os.getcwd()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eGRcW_yG2Cm",
        "outputId": "4d2d3c5d-a470-4f95-e38e-2f54aa1cc01e"
      },
      "id": "8eGRcW_yG2Cm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wd changed to: /content/drive/MyDrive/UvA Data Science/AMS_feathers_in_focus-main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1023737",
      "metadata": {
        "id": "f1023737"
      },
      "source": [
        "**Easy to find parameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06a9424e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06a9424e",
        "outputId": "e064eb58-7d0a-4477-9a40-52e17acfd49e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "batch_size = 32\n",
        "learning_rate = 0.0001\n",
        "max_lr = 0.003\n",
        "weight_decay = 0.0004\n",
        "num_epochs = 100\n",
        "num_classes = 200\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "val_split = 0.2\n",
        "seed = 42\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6111c4c0",
      "metadata": {
        "id": "6111c4c0"
      },
      "source": [
        "### Setting up dataset and dataloaders\n",
        "creating train and validation set (80:20)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b26f807",
      "metadata": {
        "id": "8b26f807"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d35a809",
      "metadata": {
        "id": "6d35a809"
      },
      "outputs": [],
      "source": [
        "class BirdDataset(Dataset):\n",
        "    def __init__(self, csv_file, root_dir, img_col_idx, label_col_idx, transform=None):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.root_dir = root_dir\n",
        "        self.img_col_idx = img_col_idx\n",
        "        self.label_col_idx = label_col_idx\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        filename = str(self.data.iloc[idx, self.img_col_idx])\n",
        "        clean_filename = filename.lstrip('/').lstrip('\\\\')\n",
        "        img_path = os.path.join(self.root_dir, clean_filename)\n",
        "\n",
        "        try:\n",
        "            image = Image.open(img_path).convert('RGB')\n",
        "        except (FileNotFoundError, OSError):\n",
        "            print(f\"Could not open {img_path}, using black image.\")\n",
        "            image = Image.new('RGB', (224, 224), (0, 0, 0))\n",
        "\n",
        "        # Raw CSV is 1-200. We subtract 1 to get 0-199 for PyTorch.\n",
        "        raw_label = int(self.data.iloc[idx, self.label_col_idx])\n",
        "        label = raw_label - 1\n",
        "\n",
        "        # Transform\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98b7c9e0",
      "metadata": {
        "id": "98b7c9e0"
      },
      "outputs": [],
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.02),\n",
        "    transforms.RandomAffine(\n",
        "        degrees=15,\n",
        "        translate=(0.1, 0.1),\n",
        "        scale=(0.8, 1.2),\n",
        "        shear=10\n",
        "    ),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        (0.485, 0.456, 0.406),\n",
        "        (0.229, 0.224, 0.225)\n",
        "    ),\n",
        "    transforms.RandomErasing(p=0.15)\n",
        "])\n",
        "\n",
        "# 2. Validation\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cee5de6d",
      "metadata": {
        "id": "cee5de6d"
      },
      "source": [
        "**Dataloaders**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d5eac62",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d5eac62",
        "outputId": "24f67ce7-bd34-4807-dc76-1d1e5654e9f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set: 3140\n",
            "Validation set: 786\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "full_train_dataset = BirdDataset('train_images.csv', 'train_images', 0, 1, transform=train_transform)\n",
        "full_val_dataset   = BirdDataset('train_images.csv', 'train_images', 0, 1, transform=val_transform)\n",
        "\n",
        "labels = full_train_dataset.data.iloc[:, 1].values - 1\n",
        "\n",
        "skf = StratifiedKFold(\n",
        "    n_splits=int(1 / val_split),\n",
        "    shuffle=True,\n",
        "    random_state=seed\n",
        ")\n",
        "\n",
        "# Take first fold\n",
        "for train_idx, val_idx in skf.split(np.zeros(len(labels)), labels):\n",
        "    break\n",
        "\n",
        "train_dataset = Subset(full_train_dataset, train_idx)\n",
        "val_dataset   = Subset(full_val_dataset,   val_idx)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"Training set: {len(train_dataset)}\")\n",
        "print(f\"Validation set: {len(val_dataset)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2209b84",
      "metadata": {
        "id": "a2209b84"
      },
      "source": [
        "**Setting up test set**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d336deb0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "d336deb0",
        "outputId": "7ab13262-311c-4457-ea1e-e8db0cecaa39"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'BirdDataset' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-199922705.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_dataset\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mBirdDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test_images_path.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test_images'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Test set: {len(test_dataset)} images to predict.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'BirdDataset' is not defined"
          ]
        }
      ],
      "source": [
        "test_dataset  = BirdDataset('test_images_path.csv', 'test_images', 1, 2, transform=val_transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "print(f\"Test set: {len(test_dataset)} images to predict.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3704c784",
      "metadata": {
        "id": "3704c784"
      },
      "source": [
        "### Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Block(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "\n",
        "        self.dw = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, in_channels, 3, padding=1, groups=in_channels, bias=False),\n",
        "            nn.BatchNorm2d(in_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.pw = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels)\n",
        "        )\n",
        "\n",
        "        self.shortcut = nn.Conv2d(in_channels, out_channels, 1, bias=False) \\\n",
        "            if in_channels != out_channels else nn.Identity()\n",
        "\n",
        "        self.activation = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.dw(x)\n",
        "        out = self.pw(out)\n",
        "        out = out + 0.5 * self.shortcut(x)\n",
        "        return self.activation(out)\n",
        "\n",
        "\n",
        "class mobile_vgg(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        self.stage1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            Block(32, 32),\n",
        "            Block(32, 64)\n",
        "        )\n",
        "        self.down1 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.stage2 = nn.Sequential(\n",
        "            Block(64, 64),\n",
        "            Block(64, 128)\n",
        "        )\n",
        "        self.down2 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.stage3 = nn.Sequential(\n",
        "            Block(128, 128),\n",
        "            Block(128, 256)\n",
        "        )\n",
        "        self.down3 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.stage4 = nn.Sequential(\n",
        "            Block(256, 256),\n",
        "            Block(256, 512)\n",
        "        )\n",
        "\n",
        "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stage1(x)\n",
        "        x = self.down1(x)\n",
        "        x = self.stage2(x)\n",
        "        x = self.down2(x)\n",
        "        x = self.stage3(x)\n",
        "        x = self.down3(x)\n",
        "        x = self.stage4(x)\n",
        "        x = self.pool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        return self.fc(x)"
      ],
      "metadata": {
        "id": "FzW6tm4rSJCp"
      },
      "id": "FzW6tm4rSJCp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = mobile_vgg(num_classes=num_classes).to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=1e-3,\n",
        "    weight_decay=1e-4\n",
        ")\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "    optimizer,\n",
        "    T_max=num_epochs,\n",
        "    eta_min=1e-6\n",
        ")\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)"
      ],
      "metadata": {
        "id": "IKZ8cnXEU47T"
      },
      "id": "IKZ8cnXEU47T",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_acc = 0.0\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "val_accuracies = []\n",
        "lrs = []\n",
        "\n",
        "print(\"Starting training...\")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    # warmup\n",
        "    if epoch < 3:  # warmup <3\n",
        "        warmup_lr = (epoch + 1) / 3 * 1e-3\n",
        "        optimizer.param_groups[0]['lr'] = warmup_lr\n",
        "\n",
        "    #training\n",
        "\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    avg_train_loss = running_loss / len(train_loader)\n",
        "    train_losses.append(avg_train_loss)\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    val_losses.append(avg_val_loss)\n",
        "\n",
        "    val_acc = 100.0 * correct / total\n",
        "    val_accuracies.append(val_acc)\n",
        "\n",
        "    # after warmup, schedular steps in\n",
        "    if epoch >= 3:\n",
        "        scheduler.step()\n",
        "\n",
        "    current_lr = optimizer.param_groups[0]['lr']\n",
        "    lrs.append(current_lr)\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {epoch+1}/{num_epochs},\"\n",
        "        f\"Train loss: {avg_train_loss:.3f}, \"\n",
        "        f\"Val loss: {avg_val_loss:.3f}, \"\n",
        "        f\"Val acc: {val_acc:.1f}%, \"\n",
        "        f\"LR: {current_lr:.6f}\"\n",
        "    )\n",
        "\n",
        "    # Save best model\n",
        "    if val_acc > best_acc:\n",
        "        best_acc = val_acc\n",
        "        torch.save(model.state_dict(), \"mobile_vgg.pth\")\n",
        "        print(f\"Saved new best model ({val_acc:.2f}%)\")\n",
        "\n",
        "print(f\"Training complete, best val acc: {best_acc:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "77Bw0o1qVYuY",
        "outputId": "25dc9e37-5e18-4468-f46b-1f61f3e96522"
      },
      "id": "77Bw0o1qVYuY",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n",
            "Epoch 1/100 | Train loss: 5.271 | Val loss: 5.186 | Val acc: 1.7% | LR: 0.000333\n",
            " --> Saved new best model (1.65%)\n",
            "Epoch 2/100 | Train loss: 5.123 | Val loss: 5.095 | Val acc: 3.2% | LR: 0.000667\n",
            " --> Saved new best model (3.18%)\n",
            "Epoch 3/100 | Train loss: 4.998 | Val loss: 5.054 | Val acc: 3.6% | LR: 0.001000\n",
            " --> Saved new best model (3.56%)\n",
            "Epoch 4/100 | Train loss: 4.901 | Val loss: 4.992 | Val acc: 4.6% | LR: 0.001000\n",
            " --> Saved new best model (4.58%)\n",
            "Epoch 5/100 | Train loss: 4.794 | Val loss: 4.970 | Val acc: 4.2% | LR: 0.000999\n",
            "Epoch 6/100 | Train loss: 4.694 | Val loss: 4.921 | Val acc: 4.3% | LR: 0.000998\n",
            "Epoch 7/100 | Train loss: 4.600 | Val loss: 4.936 | Val acc: 4.7% | LR: 0.000996\n",
            " --> Saved new best model (4.71%)\n",
            "Epoch 8/100 | Train loss: 4.481 | Val loss: 4.918 | Val acc: 5.1% | LR: 0.000994\n",
            " --> Saved new best model (5.09%)\n",
            "Epoch 9/100 | Train loss: 4.364 | Val loss: 4.721 | Val acc: 7.4% | LR: 0.000991\n",
            " --> Saved new best model (7.38%)\n",
            "Epoch 10/100 | Train loss: 4.243 | Val loss: 4.711 | Val acc: 7.6% | LR: 0.000988\n",
            " --> Saved new best model (7.63%)\n",
            "Epoch 11/100 | Train loss: 4.145 | Val loss: 4.652 | Val acc: 9.4% | LR: 0.000984\n",
            " --> Saved new best model (9.41%)\n",
            "Epoch 12/100 | Train loss: 4.042 | Val loss: 4.596 | Val acc: 10.9% | LR: 0.000980\n",
            " --> Saved new best model (10.94%)\n",
            "Epoch 13/100 | Train loss: 3.952 | Val loss: 4.732 | Val acc: 9.4% | LR: 0.000976\n",
            "Epoch 14/100 | Train loss: 3.859 | Val loss: 4.642 | Val acc: 11.2% | LR: 0.000970\n",
            " --> Saved new best model (11.20%)\n",
            "Epoch 15/100 | Train loss: 3.823 | Val loss: 4.497 | Val acc: 13.5% | LR: 0.000965\n",
            " --> Saved new best model (13.49%)\n",
            "Epoch 16/100 | Train loss: 3.699 | Val loss: 4.457 | Val acc: 13.6% | LR: 0.000959\n",
            " --> Saved new best model (13.61%)\n",
            "Epoch 17/100 | Train loss: 3.638 | Val loss: 4.431 | Val acc: 15.0% | LR: 0.000952\n",
            " --> Saved new best model (15.01%)\n",
            "Epoch 18/100 | Train loss: 3.516 | Val loss: 4.547 | Val acc: 14.8% | LR: 0.000946\n",
            "Epoch 19/100 | Train loss: 3.455 | Val loss: 4.486 | Val acc: 17.0% | LR: 0.000938\n",
            " --> Saved new best model (17.05%)\n",
            "Epoch 20/100 | Train loss: 3.383 | Val loss: 4.479 | Val acc: 15.4% | LR: 0.000930\n",
            "Epoch 21/100 | Train loss: 3.316 | Val loss: 4.374 | Val acc: 16.7% | LR: 0.000922\n",
            "Epoch 22/100 | Train loss: 3.271 | Val loss: 4.423 | Val acc: 16.2% | LR: 0.000914\n",
            "Epoch 23/100 | Train loss: 3.194 | Val loss: 4.339 | Val acc: 18.3% | LR: 0.000905\n",
            " --> Saved new best model (18.32%)\n",
            "Epoch 24/100 | Train loss: 3.108 | Val loss: 4.369 | Val acc: 19.8% | LR: 0.000895\n",
            " --> Saved new best model (19.85%)\n",
            "Epoch 25/100 | Train loss: 3.041 | Val loss: 4.412 | Val acc: 20.2% | LR: 0.000885\n",
            " --> Saved new best model (20.23%)\n",
            "Epoch 26/100 | Train loss: 2.985 | Val loss: 4.370 | Val acc: 20.1% | LR: 0.000875\n",
            "Epoch 27/100 | Train loss: 2.907 | Val loss: 4.373 | Val acc: 20.0% | LR: 0.000865\n",
            "Epoch 28/100 | Train loss: 2.862 | Val loss: 4.313 | Val acc: 19.8% | LR: 0.000854\n",
            "Epoch 29/100 | Train loss: 2.809 | Val loss: 4.250 | Val acc: 21.8% | LR: 0.000842\n",
            " --> Saved new best model (21.76%)\n",
            "Epoch 30/100 | Train loss: 2.758 | Val loss: 4.280 | Val acc: 21.0% | LR: 0.000831\n",
            "Epoch 31/100 | Train loss: 2.697 | Val loss: 4.303 | Val acc: 19.5% | LR: 0.000819\n",
            "Epoch 32/100 | Train loss: 2.657 | Val loss: 4.302 | Val acc: 21.2% | LR: 0.000807\n",
            "Epoch 33/100 | Train loss: 2.608 | Val loss: 4.337 | Val acc: 21.4% | LR: 0.000794\n",
            "Epoch 34/100 | Train loss: 2.565 | Val loss: 4.331 | Val acc: 22.6% | LR: 0.000781\n",
            " --> Saved new best model (22.65%)\n",
            "Epoch 35/100 | Train loss: 2.499 | Val loss: 4.306 | Val acc: 23.5% | LR: 0.000768\n",
            " --> Saved new best model (23.54%)\n",
            "Epoch 36/100 | Train loss: 2.446 | Val loss: 4.433 | Val acc: 22.9% | LR: 0.000755\n",
            "Epoch 37/100 | Train loss: 2.387 | Val loss: 4.403 | Val acc: 23.7% | LR: 0.000741\n",
            " --> Saved new best model (23.66%)\n",
            "Epoch 38/100 | Train loss: 2.352 | Val loss: 4.320 | Val acc: 23.8% | LR: 0.000727\n",
            " --> Saved new best model (23.79%)\n",
            "Epoch 39/100 | Train loss: 2.326 | Val loss: 4.413 | Val acc: 24.2% | LR: 0.000713\n",
            " --> Saved new best model (24.17%)\n",
            "Epoch 40/100 | Train loss: 2.268 | Val loss: 4.316 | Val acc: 27.1% | LR: 0.000699\n",
            " --> Saved new best model (27.10%)\n",
            "Epoch 41/100 | Train loss: 2.270 | Val loss: 4.241 | Val acc: 23.4% | LR: 0.000684\n",
            "Epoch 42/100 | Train loss: 2.212 | Val loss: 4.289 | Val acc: 24.8% | LR: 0.000670\n",
            "Epoch 43/100 | Train loss: 2.171 | Val loss: 4.328 | Val acc: 22.9% | LR: 0.000655\n",
            "Epoch 44/100 | Train loss: 2.131 | Val loss: 4.406 | Val acc: 23.9% | LR: 0.000640\n",
            "Epoch 45/100 | Train loss: 2.101 | Val loss: 4.327 | Val acc: 24.7% | LR: 0.000625\n",
            "Epoch 46/100 | Train loss: 2.078 | Val loss: 4.390 | Val acc: 23.5% | LR: 0.000609\n",
            "Epoch 47/100 | Train loss: 2.039 | Val loss: 4.305 | Val acc: 23.9% | LR: 0.000594\n",
            "Epoch 48/100 | Train loss: 1.997 | Val loss: 4.439 | Val acc: 25.6% | LR: 0.000579\n",
            "Epoch 49/100 | Train loss: 1.982 | Val loss: 4.431 | Val acc: 23.7% | LR: 0.000563\n",
            "Epoch 50/100 | Train loss: 1.927 | Val loss: 4.352 | Val acc: 23.4% | LR: 0.000548\n",
            "Epoch 51/100 | Train loss: 1.907 | Val loss: 4.368 | Val acc: 24.7% | LR: 0.000532\n",
            "Epoch 52/100 | Train loss: 1.902 | Val loss: 4.323 | Val acc: 25.1% | LR: 0.000516\n",
            "Epoch 53/100 | Train loss: 1.879 | Val loss: 4.311 | Val acc: 23.9% | LR: 0.000501\n",
            "Epoch 54/100 | Train loss: 1.842 | Val loss: 4.284 | Val acc: 26.0% | LR: 0.000485\n",
            "Epoch 55/100 | Train loss: 1.862 | Val loss: 4.459 | Val acc: 22.4% | LR: 0.000469\n",
            "Epoch 56/100 | Train loss: 1.805 | Val loss: 4.389 | Val acc: 26.5% | LR: 0.000453\n",
            "Epoch 57/100 | Train loss: 1.803 | Val loss: 4.371 | Val acc: 24.2% | LR: 0.000438\n",
            "Epoch 58/100 | Train loss: 1.788 | Val loss: 4.405 | Val acc: 24.6% | LR: 0.000422\n",
            "Epoch 59/100 | Train loss: 1.754 | Val loss: 4.517 | Val acc: 23.7% | LR: 0.000407\n",
            "Epoch 60/100 | Train loss: 1.761 | Val loss: 4.386 | Val acc: 23.4% | LR: 0.000392\n",
            "Epoch 61/100 | Train loss: 1.730 | Val loss: 4.401 | Val acc: 23.7% | LR: 0.000376\n",
            "Epoch 62/100 | Train loss: 1.713 | Val loss: 4.370 | Val acc: 23.8% | LR: 0.000361\n",
            "Epoch 63/100 | Train loss: 1.688 | Val loss: 4.376 | Val acc: 24.3% | LR: 0.000346\n",
            "Epoch 64/100 | Train loss: 1.688 | Val loss: 4.322 | Val acc: 23.7% | LR: 0.000331\n",
            "Epoch 65/100 | Train loss: 1.656 | Val loss: 4.426 | Val acc: 23.4% | LR: 0.000317\n",
            "Epoch 66/100 | Train loss: 1.656 | Val loss: 4.326 | Val acc: 25.4% | LR: 0.000302\n",
            "Epoch 67/100 | Train loss: 1.643 | Val loss: 4.353 | Val acc: 23.3% | LR: 0.000288\n",
            "Epoch 68/100 | Train loss: 1.614 | Val loss: 4.314 | Val acc: 24.8% | LR: 0.000274\n",
            "Epoch 69/100 | Train loss: 1.611 | Val loss: 4.312 | Val acc: 24.8% | LR: 0.000260\n",
            "Epoch 70/100 | Train loss: 1.594 | Val loss: 4.319 | Val acc: 24.3% | LR: 0.000246\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-442350823.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    786\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    789\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__getitems__\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3489396016.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# 3. Raw CSV is 1-200. We subtract 1 to get 0-199 for PyTorch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mraw_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_col_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_label\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1176\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m         \u001b[0mcheck_dict_or_set_indexers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36mcheck_dict_or_set_indexers\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m   2770\u001b[0m         \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2771\u001b[0m         \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2772\u001b[0;31m         \u001b[0;32mand\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2773\u001b[0m     ):\n\u001b[1;32m   2774\u001b[0m         raise TypeError(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2770\u001b[0m         \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2771\u001b[0m         \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2772\u001b[0;31m         \u001b[0;32mand\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2773\u001b[0m     ):\n\u001b[1;32m   2774\u001b[0m         raise TypeError(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m46MnENyWJ69"
      },
      "id": "m46MnENyWJ69",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXWeu5l52-KO",
        "outputId": "cc2d54e0-e144-4ec2-ba06-897b817f018a"
      },
      "id": "uXWeu5l52-KO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea3b3b8f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ea3b3b8f",
        "outputId": "f814e730-725b-477f-ca1d-12d0de24a155"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded!\n",
            "Saved submissions.csv!\n"
          ]
        }
      ],
      "source": [
        "model = FeatherNet(num_classes=num_classes).to(device)\n",
        "model.load_state_dict(torch.load(\"feathernet.pth\", map_location=device))\n",
        "model.eval()\n",
        "print(\"Model loaded!\")\n",
        "\n",
        "# --- Predict ---\n",
        "predictions = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, _ in test_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        predictions.extend((preds.cpu().numpy() + 1))\n",
        "\n",
        "\n",
        "# --- Save CSV ---\n",
        "submission = pd.DataFrame({\n",
        "    \"id\": range(1, len(predictions) + 1),\n",
        "    \"label\": predictions\n",
        "})\n",
        "\n",
        "submission.to_csv(\"submissions.csv\", index=False)\n",
        "print(\"Saved submissions.csv!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pdpEWl0t0-8g"
      },
      "id": "pdpEWl0t0-8g",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
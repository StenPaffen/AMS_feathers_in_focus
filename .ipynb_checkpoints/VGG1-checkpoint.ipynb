{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bf0d7cbb"
   },
   "source": [
    "### Dataset Description\n",
    "The dataset contains bird images, divided into train and test splits. The images are inside test_images and train_images folders.\n",
    "\n",
    "The labels of the training images are inside train_images.csv file. In this file, the first column is image_path and the second one is the label (1 - 200). The test_images_samples.csv includes a row id with a dummy label. The final goal of the challenge is to change the label column to the predicted label.\n",
    "\n",
    "The class_names.npy is a dictionary including the name of each label. Load the file using the following code: np.load(\"class_names.npy\", allow_pickle=True).item()\n",
    "\n",
    "The structure of the final submission should be exactly the same as the test_images_samples.csv! Otherwise, it will fail.\n",
    "\n",
    "Files\n",
    "\n",
    "- train_images - the training images\n",
    "- test_images - the test images\n",
    "- test_images_sample.csv - a sample submission file in the correct format\n",
    "- test_images_path.csv - path to test file images\n",
    "- train_images.csv - supplemental information about the data\n",
    "- class_names.npy - this file includes the name of each label\n",
    "- attributes.npy - this file includes the attributes which are extra information for each class.\n",
    "- attributes.txt - this file includes the attribute names which are extra information for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "16124d83"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h8IjUfeZFEgz",
    "outputId": "145ef640-1374-4d33-e5d4-c45469869550"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8eGRcW_yG2Cm",
    "outputId": "d271e22d-b5d3-4469-bd62-295b0e126d39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wd changed to: /content/drive/MyDrive/UvA Data Science/AMS_feathers_in_focus-main\n"
     ]
    }
   ],
   "source": [
    "base_data_path = '/content/drive/MyDrive/UvA Data Science/AMS_feathers_in_focus-main'\n",
    "\n",
    "#change gdrive wd\n",
    "os.chdir(base_data_path)\n",
    "print(f\"wd changed to: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1023737"
   },
   "source": [
    "**Easy to find parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "06a9424e",
    "outputId": "f9ebaf19-c8a2-45f8-fe00-dbc95ccb0478"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "learning_rate = 0.0001\n",
    "max_lr = 0.003\n",
    "weight_decay = 0.0004\n",
    "num_epochs = 100\n",
    "num_classes = 200\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "val_split = 0.2\n",
    "seed = 42\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "6d35a809"
   },
   "outputs": [],
   "source": [
    "class BirdDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, img_col_idx, label_col_idx, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.img_col_idx = img_col_idx\n",
    "        self.label_col_idx = label_col_idx\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = str(self.data.iloc[idx, self.img_col_idx])\n",
    "        clean_filename = filename.lstrip('/').lstrip('\\\\')\n",
    "        img_path = os.path.join(self.root_dir, clean_filename)\n",
    "\n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "        except (FileNotFoundError, OSError):\n",
    "            print(f\"Could not open {img_path}, using black image.\")\n",
    "            image = Image.new('RGB', (224, 224), (0, 0, 0))\n",
    "\n",
    "        # Raw CSV is 1-200. We subtract 1 to get 0-199 for PyTorch.\n",
    "        raw_label = int(self.data.iloc[idx, self.label_col_idx])\n",
    "        label = raw_label - 1\n",
    "\n",
    "        # Transform\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "98b7c9e0"
   },
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.8, 1.2), shear=10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "# 2. Validation\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X_IgVyDXrwdX",
    "outputId": "c3cefd41-8a49-4b28-98f9-4b3cd3493bf0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 3140\n",
      "Validation set: 786\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "full_train_dataset = BirdDataset('train_images.csv', 'train_images', 0, 1, transform=train_transform)\n",
    "full_val_dataset   = BirdDataset('train_images.csv', 'train_images', 0, 1, transform=val_transform)\n",
    "\n",
    "labels = full_train_dataset.data.iloc[:, 1].values - 1\n",
    "\n",
    "skf = StratifiedKFold(\n",
    "    n_splits=int(1 / val_split),\n",
    "    shuffle=True,\n",
    "    random_state=seed\n",
    ")\n",
    "\n",
    "# Take the first fold\n",
    "for train_idx, val_idx in skf.split(np.zeros(len(labels)), labels):\n",
    "    break\n",
    "\n",
    "train_dataset = Subset(full_train_dataset, train_idx)\n",
    "val_dataset   = Subset(full_val_dataset,   val_idx)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Training set: {len(train_dataset)}\")\n",
    "print(f\"Validation set: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d336deb0",
    "outputId": "2484b9c8-896f-4bf8-996b-bdeb89aabad5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: 4000 images to predict.\n"
     ]
    }
   ],
   "source": [
    "test_dataset  = BirdDataset('test_images_path.csv', 'test_images', 1, 2, transform=val_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"Test set: {len(test_dataset)} images to predict.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "c5080426"
   },
   "outputs": [],
   "source": [
    "class VGG_style(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        def cnblock(in_channels, out_channels):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            )\n",
    "        self.features = nn.Sequential(\n",
    "            cnblock(3, 64),\n",
    "            cnblock(64, 128),\n",
    "            cnblock(128, 256),\n",
    "            cnblock(256, 512),\n",
    "            cnblock(512, 512)\n",
    "        )\n",
    "\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(2048, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.global_pool(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "onoiLCetvjSA"
   },
   "outputs": [],
   "source": [
    "model = VGG_style(num_classes=num_classes).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='max',\n",
    "    factor=0.6,\n",
    "    patience=2,\n",
    "    min_lr=1e-6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "id": "au-TKCnAvtJY",
    "outputId": "6bb51724-6964-41e6-e3f8-a18af2ac9151"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch 1/100, Train Loss: 5.281, Val Loss: 5.163, Val Acc: 2.0%, LR: 0.00010\n",
      "Saved new best model (2.04%)\n",
      "Epoch 2/100, Train Loss: 5.114, Val Loss: 5.040, Val Acc: 2.4%, LR: 0.00010\n",
      "Saved new best model (2.42%)\n",
      "Epoch 3/100, Train Loss: 5.002, Val Loss: 4.973, Val Acc: 3.6%, LR: 0.00010\n",
      "Saved new best model (3.56%)\n",
      "Epoch 4/100, Train Loss: 4.936, Val Loss: 4.914, Val Acc: 3.1%, LR: 0.00010\n",
      "Epoch 5/100, Train Loss: 4.859, Val Loss: 4.878, Val Acc: 4.7%, LR: 0.00010\n",
      "Saved new best model (4.71%)\n",
      "Epoch 6/100, Train Loss: 4.803, Val Loss: 4.806, Val Acc: 3.9%, LR: 0.00010\n",
      "Epoch 7/100, Train Loss: 4.743, Val Loss: 4.806, Val Acc: 4.1%, LR: 0.00010\n",
      "Epoch 8/100, Train Loss: 4.682, Val Loss: 4.732, Val Acc: 3.6%, LR: 0.00006\n",
      "Epoch 9/100, Train Loss: 4.600, Val Loss: 4.762, Val Acc: 3.9%, LR: 0.00006\n",
      "Epoch 10/100, Train Loss: 4.556, Val Loss: 4.683, Val Acc: 4.7%, LR: 0.00006\n",
      "Epoch 11/100, Train Loss: 4.509, Val Loss: 4.625, Val Acc: 5.3%, LR: 0.00006\n",
      "Saved new best model (5.34%)\n",
      "Epoch 12/100, Train Loss: 4.468, Val Loss: 4.674, Val Acc: 4.1%, LR: 0.00006\n",
      "Epoch 13/100, Train Loss: 4.456, Val Loss: 4.632, Val Acc: 3.9%, LR: 0.00006\n",
      "Epoch 14/100, Train Loss: 4.432, Val Loss: 4.565, Val Acc: 6.4%, LR: 0.00006\n",
      "Saved new best model (6.36%)\n",
      "Epoch 15/100, Train Loss: 4.386, Val Loss: 4.476, Val Acc: 6.0%, LR: 0.00006\n",
      "Epoch 16/100, Train Loss: 4.330, Val Loss: 4.485, Val Acc: 6.5%, LR: 0.00006\n",
      "Saved new best model (6.49%)\n",
      "Epoch 17/100, Train Loss: 4.272, Val Loss: 4.454, Val Acc: 6.5%, LR: 0.00006\n",
      "Epoch 18/100, Train Loss: 4.235, Val Loss: 4.466, Val Acc: 6.9%, LR: 0.00006\n",
      "Saved new best model (6.87%)\n",
      "Epoch 19/100, Train Loss: 4.190, Val Loss: 4.406, Val Acc: 6.7%, LR: 0.00006\n",
      "Epoch 20/100, Train Loss: 4.158, Val Loss: 4.322, Val Acc: 7.4%, LR: 0.00006\n",
      "Saved new best model (7.38%)\n",
      "Epoch 21/100, Train Loss: 4.096, Val Loss: 4.283, Val Acc: 10.2%, LR: 0.00006\n",
      "Saved new best model (10.18%)\n",
      "Epoch 22/100, Train Loss: 4.037, Val Loss: 4.238, Val Acc: 8.8%, LR: 0.00006\n",
      "Epoch 23/100, Train Loss: 4.005, Val Loss: 4.196, Val Acc: 9.0%, LR: 0.00006\n",
      "Epoch 24/100, Train Loss: 3.958, Val Loss: 4.222, Val Acc: 9.7%, LR: 0.00004\n",
      "Epoch 25/100, Train Loss: 3.884, Val Loss: 4.105, Val Acc: 9.2%, LR: 0.00004\n",
      "Epoch 26/100, Train Loss: 3.806, Val Loss: 4.148, Val Acc: 9.5%, LR: 0.00004\n",
      "Epoch 27/100, Train Loss: 3.778, Val Loss: 4.106, Val Acc: 11.1%, LR: 0.00004\n",
      "Saved new best model (11.07%)\n",
      "Epoch 28/100, Train Loss: 3.775, Val Loss: 4.065, Val Acc: 11.2%, LR: 0.00004\n",
      "Saved new best model (11.20%)\n",
      "Epoch 29/100, Train Loss: 3.713, Val Loss: 4.042, Val Acc: 12.2%, LR: 0.00004\n",
      "Saved new best model (12.21%)\n",
      "Epoch 30/100, Train Loss: 3.665, Val Loss: 3.982, Val Acc: 11.7%, LR: 0.00004\n",
      "Epoch 31/100, Train Loss: 3.618, Val Loss: 4.063, Val Acc: 11.7%, LR: 0.00004\n",
      "Epoch 32/100, Train Loss: 3.598, Val Loss: 3.918, Val Acc: 12.5%, LR: 0.00004\n",
      "Saved new best model (12.47%)\n",
      "Epoch 33/100, Train Loss: 3.578, Val Loss: 3.934, Val Acc: 12.0%, LR: 0.00004\n",
      "Epoch 34/100, Train Loss: 3.517, Val Loss: 3.863, Val Acc: 14.0%, LR: 0.00004\n",
      "Saved new best model (13.99%)\n",
      "Epoch 35/100, Train Loss: 3.527, Val Loss: 3.953, Val Acc: 12.0%, LR: 0.00004\n",
      "Epoch 36/100, Train Loss: 3.472, Val Loss: 3.817, Val Acc: 14.4%, LR: 0.00004\n",
      "Saved new best model (14.38%)\n",
      "Epoch 37/100, Train Loss: 3.409, Val Loss: 3.893, Val Acc: 13.1%, LR: 0.00004\n",
      "Epoch 38/100, Train Loss: 3.434, Val Loss: 3.998, Val Acc: 13.0%, LR: 0.00004\n",
      "Epoch 39/100, Train Loss: 3.393, Val Loss: 3.785, Val Acc: 15.9%, LR: 0.00004\n",
      "Saved new best model (15.90%)\n",
      "Epoch 40/100, Train Loss: 3.327, Val Loss: 3.876, Val Acc: 15.8%, LR: 0.00004\n",
      "Epoch 41/100, Train Loss: 3.307, Val Loss: 3.837, Val Acc: 15.0%, LR: 0.00004\n",
      "Epoch 42/100, Train Loss: 3.220, Val Loss: 3.834, Val Acc: 14.1%, LR: 0.00002\n",
      "Epoch 43/100, Train Loss: 3.182, Val Loss: 3.673, Val Acc: 17.7%, LR: 0.00002\n",
      "Saved new best model (17.68%)\n",
      "Epoch 44/100, Train Loss: 3.131, Val Loss: 3.714, Val Acc: 17.6%, LR: 0.00002\n",
      "Epoch 45/100, Train Loss: 3.107, Val Loss: 3.743, Val Acc: 16.9%, LR: 0.00002\n",
      "Epoch 46/100, Train Loss: 3.088, Val Loss: 3.663, Val Acc: 18.2%, LR: 0.00002\n",
      "Saved new best model (18.19%)\n",
      "Epoch 47/100, Train Loss: 3.066, Val Loss: 3.714, Val Acc: 18.1%, LR: 0.00002\n",
      "Epoch 48/100, Train Loss: 3.064, Val Loss: 3.692, Val Acc: 17.8%, LR: 0.00002\n",
      "Epoch 49/100, Train Loss: 3.058, Val Loss: 3.691, Val Acc: 16.8%, LR: 0.00001\n",
      "Epoch 50/100, Train Loss: 2.965, Val Loss: 3.573, Val Acc: 19.5%, LR: 0.00001\n",
      "Saved new best model (19.47%)\n",
      "Epoch 51/100, Train Loss: 2.942, Val Loss: 3.574, Val Acc: 19.7%, LR: 0.00001\n",
      "Saved new best model (19.72%)\n",
      "Epoch 52/100, Train Loss: 2.934, Val Loss: 3.581, Val Acc: 19.3%, LR: 0.00001\n",
      "Epoch 53/100, Train Loss: 2.895, Val Loss: 3.613, Val Acc: 17.7%, LR: 0.00001\n",
      "Epoch 54/100, Train Loss: 2.850, Val Loss: 3.535, Val Acc: 21.5%, LR: 0.00001\n",
      "Saved new best model (21.50%)\n",
      "Epoch 55/100, Train Loss: 2.847, Val Loss: 3.567, Val Acc: 18.6%, LR: 0.00001\n",
      "Epoch 56/100, Train Loss: 2.880, Val Loss: 3.592, Val Acc: 20.9%, LR: 0.00001\n",
      "Epoch 57/100, Train Loss: 2.834, Val Loss: 3.552, Val Acc: 20.5%, LR: 0.00001\n",
      "Epoch 58/100, Train Loss: 2.805, Val Loss: 3.558, Val Acc: 19.0%, LR: 0.00001\n",
      "Epoch 59/100, Train Loss: 2.785, Val Loss: 3.558, Val Acc: 19.0%, LR: 0.00001\n",
      "Epoch 60/100, Train Loss: 2.753, Val Loss: 3.542, Val Acc: 20.5%, LR: 0.00000\n",
      "Epoch 61/100, Train Loss: 2.761, Val Loss: 3.497, Val Acc: 20.7%, LR: 0.00000\n",
      "Epoch 62/100, Train Loss: 2.726, Val Loss: 3.510, Val Acc: 20.5%, LR: 0.00000\n",
      "Epoch 63/100, Train Loss: 2.705, Val Loss: 3.512, Val Acc: 21.2%, LR: 0.00000\n",
      "Epoch 64/100, Train Loss: 2.712, Val Loss: 3.527, Val Acc: 21.0%, LR: 0.00000\n",
      "Epoch 65/100, Train Loss: 2.682, Val Loss: 3.519, Val Acc: 21.0%, LR: 0.00000\n",
      "Epoch 66/100, Train Loss: 2.682, Val Loss: 3.524, Val Acc: 20.2%, LR: 0.00000\n",
      "Epoch 67/100, Train Loss: 2.655, Val Loss: 3.509, Val Acc: 20.4%, LR: 0.00000\n",
      "Epoch 68/100, Train Loss: 2.691, Val Loss: 3.502, Val Acc: 21.0%, LR: 0.00000\n",
      "Epoch 69/100, Train Loss: 2.684, Val Loss: 3.542, Val Acc: 19.8%, LR: 0.00000\n",
      "Epoch 70/100, Train Loss: 2.650, Val Loss: 3.522, Val Acc: 21.0%, LR: 0.00000\n",
      "Epoch 71/100, Train Loss: 2.670, Val Loss: 3.539, Val Acc: 20.5%, LR: 0.00000\n",
      "Epoch 72/100, Train Loss: 2.647, Val Loss: 3.506, Val Acc: 20.7%, LR: 0.00000\n",
      "Epoch 73/100, Train Loss: 2.658, Val Loss: 3.518, Val Acc: 20.6%, LR: 0.00000\n",
      "Epoch 74/100, Train Loss: 2.665, Val Loss: 3.494, Val Acc: 21.4%, LR: 0.00000\n",
      "Epoch 75/100, Train Loss: 2.654, Val Loss: 3.502, Val Acc: 21.5%, LR: 0.00000\n",
      "Epoch 76/100, Train Loss: 2.661, Val Loss: 3.518, Val Acc: 20.5%, LR: 0.00000\n",
      "Epoch 77/100, Train Loss: 2.656, Val Loss: 3.522, Val Acc: 20.1%, LR: 0.00000\n",
      "Epoch 78/100, Train Loss: 2.652, Val Loss: 3.517, Val Acc: 20.5%, LR: 0.00000\n",
      "Epoch 79/100, Train Loss: 2.630, Val Loss: 3.520, Val Acc: 20.6%, LR: 0.00000\n",
      "Epoch 80/100, Train Loss: 2.628, Val Loss: 3.523, Val Acc: 19.8%, LR: 0.00000\n",
      "Epoch 81/100, Train Loss: 2.650, Val Loss: 3.512, Val Acc: 21.0%, LR: 0.00000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     23\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 25\u001b[0m     running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m avg_train_loss \u001b[38;5;241m=\u001b[39m running_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n\u001b[0;32m     28\u001b[0m train_losses\u001b[38;5;241m.\u001b[39mappend(avg_train_loss)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_acc = 0.0\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "lrs = []\n",
    "\n",
    "print(\"Starting training...\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # train\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    # val\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    val_acc = 100.0 * correct / total\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    scheduler.step(val_acc)\n",
    "\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    lrs.append(current_lr)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}/{num_epochs}, \"\n",
    "        f\"Train Loss: {avg_train_loss:.3f}, \"\n",
    "        f\"Val Loss: {avg_val_loss:.3f}, \"\n",
    "        f\"Val Acc: {val_acc:.1f}%, \"\n",
    "        f\"LR: {current_lr:.5f}\"\n",
    "    )\n",
    "\n",
    "    # save best model\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"vgg_style.pth\")\n",
    "        print(f\"Saved new best model ({val_acc:.2f}%)\")\n",
    "\n",
    "print(f\"Training complete | Best val acc: {best_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
